{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "%run dihiggs_dataset.ipynb\n",
    "\n",
    "import argparse\n",
    "import os\n",
    "import numpy as np\n",
    "import math\n",
    "import sys\n",
    "\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.utils import save_image\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F   # NOTE: I don't think this is used\n",
    "import torch.autograd as autograd\n",
    "import torch\n",
    "\n",
    "from IPython import display\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "#\n",
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "os.makedirs(\"images\", exist_ok=True)\n",
    "\n",
    "#parser = argparse.ArgumentParser()\n",
    "\n",
    "\"\"\"\n",
    "parser.add_argument(\"--n_epochs\", type=int, default=200, help=\"number of epochs of training\")\n",
    "parser.add_argument(\"--batch_size\", type=int, default=64, help=\"size of the batches\")\n",
    "parser.add_argument(\"--lr\", type=float, default=0.0002, help=\"adam: learning rate\")\n",
    "parser.add_argument(\"--b1\", type=float, default=0.5, help=\"adam: decay of first order momentum of gradient\")\n",
    "parser.add_argument(\"--b2\", type=float, default=0.999, help=\"adam: decay of first order momentum of gradient\")\n",
    "parser.add_argument(\"--n_cpu\", type=int, default=8, help=\"number of cpu threads to use during batch generation\")\n",
    "parser.add_argument(\"--latent_dim\", type=int, default=100, help=\"dimensionality of the latent space\")\n",
    "parser.add_argument(\"--img_size\", type=int, default=28, help=\"size of each image dimension\")\n",
    "parser.add_argument(\"--channels\", type=int, default=1, help=\"number of image channels\")\n",
    "parser.add_argument(\"--n_critic\", type=int, default=5, help=\"number of training steps for discriminator per iter\")\n",
    "parser.add_argument(\"--clip_value\", type=float, default=0.01, help=\"lower and upper clip value for disc. weights\")\n",
    "parser.add_argument(\"--sample_interval\", type=int, default=400, help=\"interval betwen image samples\")\n",
    "\"\"\"\n",
    "#opt = parser.parse_args()\n",
    "#print(opt)\n",
    "class opt():   # Class used for optimizers in the future. Defines all variables and stuff needed.\n",
    "    n_epochs = 20000   # an epoch is the number of times it works through the entire training set\n",
    "    #batch_size = 1000   # the training set is broken up into batches, \n",
    "                        # and the average loss is used from a given batch for back propagation\n",
    "    lr = 0.001   # learning rate (how much to change based on error)\n",
    "    b1 = 0.9     # Used for Adam. Exponential decay rate for the first moment. \n",
    "    b2 = 0.999   # Used for Adam. Exponential decay rate for the second moment estimates (gradient squared)\n",
    "    #NOTE: The default epsilon for torch.optim.adam is 1e-8, so I will just leave it that way\n",
    "    \n",
    "    #n_cpu = 2   # not used rn\n",
    "    latent_dim = 100 #size of noise input to generator (latent space) \n",
    "    #img_size = 28\n",
    "    # channels = 1   # Only used for img_shape right below, and img_shape isn't needed\n",
    "    n_critic = 5   # The generator is trained after this many critic steps\n",
    "    #   clip_value = 0.01   # No other usages rn. \n",
    "    sample_interval = 400   # Determines when a to save the image(s?) generated\n",
    "\n",
    "# img_shape = (opt.channels, opt.img_size, opt.img_size)   # Not used rn\n",
    "\n",
    "cuda = True if torch.cuda.is_available() else False\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    \"\"\"\n",
    "    Create hidden layers. Apply normalization. Apply leaky relu. \n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()   \n",
    "\n",
    "        def block(in_feat, out_feat, normalize=True):   # This function creates the hidden layers\n",
    "            layers = [nn.Linear(in_feat, out_feat)]   # layer is a hidden layer. Takes input\n",
    "                                                      # (batch_size,in_feat) and give an output (batch_size,out_feat)\n",
    "            if normalize:\n",
    "                layers.append(nn.BatchNorm1d(out_feat, 0.8))   # adds normalization to what Layers does to input and comes out in\n",
    "                                                               # size (batch_size,out_feat). I think this does bn1d(linear(input))\n",
    "            layers.append(nn.LeakyReLU(0.2, inplace=True))   # inplace means just modify input, don't allocate more memory\n",
    "            return layers\n",
    "\n",
    "\n",
    "\n",
    "        \"\"\"\n",
    "        stores layers and functions applied to layers\n",
    "        \"\"\"       \n",
    "        self.model = nn.Sequential(   \n",
    "            *block(opt.latent_dim, 128, normalize=False),   # first layer\n",
    "            *block(128, 256),   # second layer\n",
    "            *block(256, 512),   # 3rd layer\n",
    "            *block(512, 1024),   # 4th layer\n",
    "            nn.Linear(1024, 784),   # final layer. Output is size 25\n",
    "            nn.Tanh()   # Using tanh for final output (why tanh vs leaky relu?)\n",
    "        )\n",
    "\n",
    "    def forward(self, z):\n",
    "        \"\"\"\n",
    "        applies layers to input to get img\n",
    "        \"\"\"\n",
    "        img = self.model(z)   # applies model (layers and functions on layers) to z\n",
    "        #img = img.view(img.shape[0], *img_shape)\n",
    "        return img\n",
    "\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    \"\"\"\n",
    "    Discriminator/critic layers\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()   # Just uses the module constructor with name Discriminator \n",
    "\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(784, 512),   # first layer\n",
    "            nn.LeakyReLU(0.2, inplace=True),   # apply leaky relu to layer\n",
    "            nn.Linear(512, 256),   # 2nd layer\n",
    "            nn.LeakyReLU(0.2, inplace=True),   # apply leaky relu to layer\n",
    "            nn.Linear(256, 1),   # Final layer to give output. Output is size 1 (validity score)\n",
    "                                 # NOTE: weird to end with comma\n",
    "        )\n",
    "\n",
    "    def forward(self, img):\n",
    "        \"\"\"\n",
    "        applies model to image and gives validity score\n",
    "        \"\"\"\n",
    "        img_flat = img.view(img.shape[0], -1)   # TODO: Figure out what this does \n",
    "        validity = self.model(img_flat)   # calculates validity score\n",
    "        return validity\n",
    "\n",
    "\n",
    "# ******* OUT OF CLASSES NOW ************\n",
    "\n",
    "\n",
    "# Loss weight for gradient penalty\n",
    "lambda_gp = 10\n",
    "\n",
    "# Initialize generator and discriminator\n",
    "generator = Generator()\n",
    "discriminator = Discriminator()\n",
    "\n",
    "if cuda:\n",
    "    generator.cuda()\n",
    "    discriminator.cuda()\n",
    "    \n",
    "    \n",
    "training_dataset = datasets.MNIST(\"\", train = True, download = True, transform = transforms.Compose([transforms.ToTensor()]))\n",
    "testing_dataset = datasets.MNIST(\"\", train = False, download = True, transform = transforms.Compose([transforms.ToTensor()]))\n",
    "# testing_dataset -> out-of-sample testing data to run through nn.If you run in sample data only, won't be able to tell\n",
    "# whether The nn has overfitted\n",
    "train_set = torch.utils.data.DataLoader(training_dataset, batch_size=10, shuffle = True)\n",
    "test_set = torch.utils.data.DataLoader(testing_dataset, batch_size=10, shuffle = True) \n",
    "\n",
    "## Configure data loader - CHANGE\n",
    "#os.makedirs(\"./data/\", exist_ok=True)\n",
    "#dataloader = torch.utils.data.DataLoader(\n",
    " #   DiHiggsSignalMCDataset('./DiHiggs Data', generator_level = False),\n",
    "  #  batch_size=opt.batch_size,\n",
    "  #  shuffle=True,\n",
    "#)\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mnist_data():\n",
    "    compose = transforms.Compose(\n",
    "        [transforms.ToTensor(),\n",
    "         transforms.Normalize([0.5], [0.5])\n",
    "        ])\n",
    "    out_dir = '{}/dataset'.format(DATA_FOLDER)\n",
    "    return datasets.MNIST(root=out_dir, train=True, transform=compose, download=True)\n",
    "\n",
    "# def mnist_data():\n",
    "#     compose = transforms.Compose(\n",
    "#         [transforms.ToTensor(),\n",
    "#          transforms.Normalize((.5,), (.5,))\n",
    "#         ])\n",
    "#     out_dir = '{}/dataset'.format(DATA_FOLDER)\n",
    "#     return datasets.MNIST(root=out_dir, train=True, transform=compose, download=True)\n",
    "\n",
    "def noise(size):\n",
    "    '''\n",
    "    Generates a 1-d vector of gaussian sampled random values\n",
    "    '''\n",
    "    n = Variable(torch.randn(size, 100))\n",
    "    if torch.cuda.is_available(): return n.cuda()\n",
    "    return n\n",
    "\n",
    "def images_to_vectors(images):\n",
    "    return images.view(images.size(0), 784)\n",
    "\n",
    "def vectors_to_images(vectors):\n",
    "    return vectors.view(vectors.size(0), 1, 28, 28)\n",
    "\n",
    "def ones_target(size):\n",
    "    '''\n",
    "    Tensor containing ones, with shape = size\n",
    "    '''\n",
    "    data = Variable(torch.ones(size, 1))\n",
    "    if torch.cuda.is_available(): return data.cuda()\n",
    "    return data\n",
    "\n",
    "def zeros_target(size):\n",
    "    '''\n",
    "    Tensor containing zeros, with shape = size\n",
    "    '''\n",
    "    data = Variable(torch.zeros(size, 1))\n",
    "    if torch.cuda.is_available(): return data.cuda()\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_gradient_penalty(D, real_samples, fake_samples):   # TODO: Find out why these are .data\n",
    "    \"\"\"\n",
    "    Calculates the gradient penalty loss for WGAN GP\n",
    "    D input will be discrimantor function\n",
    "    real_samples and fake_samples are from reality and generator. Both are sent in via memory location of buffer\n",
    "    \n",
    "    \"\"\"\n",
    "    # Random weight term for interpolation between real and fake samples (how much of each)\n",
    "    alpha = Tensor(np.random.random((real_samples.size(0),1)))   # This is a tensor designating which to use where\n",
    "\n",
    "  #  print(alpha.shape)\n",
    "    # Get random interpolation between real and fake samples\n",
    "   # print(real_samples.shape)\n",
    "    \n",
    "    # Gets some of real and some of fake samples for gradient penalty calculation\n",
    "    interpolates = (alpha * real_samples + ((1 - alpha) * fake_samples)).requires_grad_(True)\n",
    "    # .requires grad is something attached to all tensors and can be used to speed up (by making false I think)\n",
    "    # It is automatically false, but if you need gradient then set to be true\n",
    "    # TODO: Understand how this statement works\n",
    "\n",
    "   # print(interpolates.shape)\n",
    "\n",
    "    d_interpolates = D(interpolates)   # Run discriminator on interpolates to get validity scores\n",
    "    fake = Variable(Tensor(real_samples.shape[0], 1).fill_(1.0), requires_grad=False)   \n",
    "    \n",
    "    # Get gradient w.r.t. interpolates (uses inputs and outputs to calculate )\n",
    "    gradients = autograd.grad(\n",
    "        outputs=d_interpolates,\n",
    "        inputs=interpolates,\n",
    "        grad_outputs=fake,   # TODO: figure out what this is for\n",
    "        create_graph=True,\n",
    "        retain_graph=True,\n",
    "        only_inputs=True,\n",
    "    )[0]\n",
    "    gradients = gradients.view(gradients.size(0), -1)   # still need to figure out view thing\n",
    "    gradient_penalty = ((gradients.norm(2, dim=1) - 1) ** 2).mean()   # Normalize and then average gradients for penalty\n",
    "    return gradient_penalty\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_FOLDER = './torch_data/VGAN/MNIST'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "data = mnist_data()\n",
    "# Create loader with data, so that we can iterate over it\n",
    "train_set = torch.utils.data.DataLoader(data, batch_size=100, shuffle=True)\n",
    "# Num batches\n",
    "num_batches = len(train_set)\n",
    "\n",
    "\n",
    "num_test_samples = 16\n",
    "test_noise = noise(num_test_samples)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3037574\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "[Epoch 1/20000] [Batch 210/600] [D loss: -6.163323] [G loss: 3.483780]\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "[Epoch 1/20000] [Batch 220/600] [D loss: -5.735228] [G loss: 5.903938]\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "[Epoch 1/20000] [Batch 230/600] [D loss: -6.450203] [G loss: 5.914916]\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "[Epoch 1/20000] [Batch 240/600] [D loss: -5.447195] [G loss: 2.632954]\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "[Epoch 1/20000] [Batch 250/600] [D loss: -6.319954] [G loss: 3.954702]\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "[Epoch 1/20000] [Batch 260/600] [D loss: -5.966972] [G loss: 5.910229]\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "[Epoch 1/20000] [Batch 270/600] [D loss: -6.095169] [G loss: 5.061616]\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "[Epoch 1/20000] [Batch 280/600] [D loss: -5.918352] [G loss: 3.696320]\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "[Epoch 1/20000] [Batch 290/600] [D loss: -6.453012] [G loss: 8.244892]\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "[Epoch 1/20000] [Batch 300/600] [D loss: -7.003899] [G loss: 7.682364]\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "[Epoch 1/20000] [Batch 310/600] [D loss: -6.519662] [G loss: 8.038210]\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "[Epoch 1/20000] [Batch 320/600] [D loss: -7.391585] [G loss: 8.562377]\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "[Epoch 1/20000] [Batch 330/600] [D loss: -6.218765] [G loss: 8.668348]\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "[Epoch 1/20000] [Batch 340/600] [D loss: -6.708611] [G loss: 9.226110]\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "[Epoch 1/20000] [Batch 350/600] [D loss: -6.250809] [G loss: 8.012240]\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "[Epoch 1/20000] [Batch 360/600] [D loss: -6.367117] [G loss: 9.055887]\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "[Epoch 1/20000] [Batch 370/600] [D loss: -6.550021] [G loss: 7.022849]\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "[Epoch 1/20000] [Batch 380/600] [D loss: -6.748294] [G loss: 6.343242]\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "[Epoch 1/20000] [Batch 390/600] [D loss: -6.510870] [G loss: 7.821756]\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "[Epoch 1/20000] [Batch 400/600] [D loss: -6.069776] [G loss: 8.621467]\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "[Epoch 1/20000] [Batch 410/600] [D loss: -6.537545] [G loss: 7.024827]\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "[Epoch 1/20000] [Batch 420/600] [D loss: -6.591006] [G loss: 6.025823]\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "[Epoch 1/20000] [Batch 430/600] [D loss: -6.484665] [G loss: 5.893942]\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "# Optimizers (Adam optimizers are an alternative to stochastic gradient descent. TODO learn more about them)\n",
    "optimizer_G = torch.optim.Adam(generator.parameters(), lr=opt.lr, betas=(opt.b1, opt.b2))   \n",
    "optimizer_D = torch.optim.Adam(discriminator.parameters(), lr=opt.lr, betas=(opt.b1, opt.b2))\n",
    "\n",
    "Tensor = torch.cuda.FloatTensor if cuda else torch.FloatTensor\n",
    "\n",
    "dis_error = []\n",
    "gen_error = []\n",
    "\n",
    "# ----------\n",
    "#  Training\n",
    "# ----------\n",
    "\n",
    "batches_done = 0   # Counter for batches\n",
    "for epoch in range(opt.n_epochs):   # Loop through all epochs\n",
    "    for i, (x,_) in enumerate(train_set): # x is in dataloader (a batch I think). i\n",
    "                                       # is the index of x (number of times critic is trained this epoch)\n",
    "        #if cuda:\n",
    "         #   x = x.cuda()\n",
    "\n",
    "        # Configure input\n",
    "        #x = np.ndarray(x)\n",
    "        print(type(x))\n",
    "        real_imgs = Variable(images_to_vectors(x.cuda())) #\n",
    "        #print(real_imgs)\n",
    "        #real_imgs = Variable(images_to_vectors(x).type(Tensor))   # Variable is a wrapper for the Tensor x was just made into\n",
    "\n",
    "        # ---------------------\n",
    "        #  Train Discriminator\n",
    "        # ---------------------\n",
    "\n",
    "        optimizer_D.zero_grad()   # Make gradients zero so they don't accumulate\n",
    "\n",
    "        # Sample noise (latent space) to make generator input\n",
    "        z = Variable(Tensor(np.random.normal(0, 1, (x.shape[0], opt.latent_dim))).cuda())   # Once again Variable wraps the Tensor\n",
    "\n",
    "        # Generate a batch of images from the latent space sampled\n",
    "        fake_imgs = generator(z)\n",
    "        #fake_imgs = generator(noise(x.size(0)))\n",
    "        #print(fake_imgs[0])\n",
    "\n",
    "        # Calculate validity score for real images\n",
    "        real_validity = discriminator(real_imgs)\n",
    "\n",
    "        # Calculate validity score for fake images\n",
    "        fake_validity = discriminator(fake_imgs)\n",
    "\n",
    "        # Calculate gradient penalty\n",
    "        gradient_penalty = compute_gradient_penalty(discriminator, real_imgs.data, fake_imgs.data)\n",
    "        # TODO: figure out why .data is used\n",
    "\n",
    "        # Calculate loss for critic (Adversarial loss)\n",
    "        d_loss = -torch.mean(real_validity) + torch.mean(fake_validity) + lambda_gp * gradient_penalty\n",
    "\n",
    "        d_loss.backward()   # Do back propagation \n",
    "        optimizer_D.step()   # Update parameters based on gradients for individuals\n",
    "\n",
    "        optimizer_G.zero_grad()   # Resets gradients for generator to be zero to avoid accumulation\n",
    "\n",
    "        # Train the generator every n_critic steps\n",
    "        if i % opt.n_critic == 0:\n",
    "\n",
    "            # -----------------\n",
    "            #  Train Generator\n",
    "            # -----------------\n",
    "\n",
    "            # Generate a batch of images\n",
    "            fake_imgs = generator(z)\n",
    "\n",
    "            # Loss measures generator's ability to fool the discriminator\n",
    "            # Train on fake images\n",
    "            fake_validity = discriminator(fake_imgs)\n",
    "            g_loss = -torch.mean(fake_validity)\n",
    "\n",
    "            g_loss.backward()\n",
    "            optimizer_G.step()\n",
    "\n",
    "\n",
    "            # ----------------------------\n",
    "            # Save stuff when time is right\n",
    "            # ----------------------------\n",
    "            if batches_done % 10 == 0:\n",
    "                print(\n",
    "                    \"[Epoch %d/%d] [Batch %d/%d] [D loss: %f] [G loss: %f]\"\n",
    "                    % (epoch, opt.n_epochs, i, len(train_set), d_loss.item(), g_loss.item())\n",
    "                )\n",
    "\n",
    "            if batches_done % opt.sample_interval == 0:\n",
    "                save_image(fake_imgs.data[:728], \"images/%d.png\" % batches_done, nrow=5, normalize=True)\n",
    "                # Display stuff\n",
    "                display.clear_output(True)\n",
    "\n",
    "                dis_error.append(d_loss.item())\n",
    "                gen_error.append(g_loss.item())\n",
    "                print(g_loss.data.cpu().numpy())\n",
    "                # Display Images\n",
    "                test_images = vectors_to_images(generator(test_noise)).data.cpu()\n",
    "                # Display status Logs\n",
    "\n",
    "                # Model Checkpoints\n",
    "                fig, axs = plt.subplots(2)\n",
    "                axs[0].plot(batches_done)\n",
    "                axs[1].plot(batches_done)\n",
    "                axs[0].set_title(\"Discriminator Error\")\n",
    "                axs[0].set_xlabel(\"Batch #\")\n",
    "                axs[0].set_ylabel(\"Error\")\n",
    "                axs[0].set_xscale('log')\n",
    "                axs[1].set_title(\"Generator Error\")\n",
    "                axs[1].set_xlabel(\"Batch #\")\n",
    "                axs[1].set_ylabel(\"Error\")\n",
    "                axs[1].set_xscale('log')\n",
    "                fig.tight_layout()\n",
    "                plt.show()\n",
    "\n",
    "            batches_done += opt.n_critic\n",
    "            \n",
    "\n",
    "            \n",
    "            \n",
    "            \n",
    "    if epoch % 10 == 0:\n",
    "        z = Variable(Tensor(np.random.normal(0, 1, (300000, opt.latent_dim))))\n",
    "        fake_data = generator(z)\n",
    "        np.save('./mnist_data/{num_batches}.npy'.format(num_batches=batches_done), fake_data.cpu().detach().numpy())\n",
    "    \n",
    "    #if epoch % 0 == 0 or epoch == 999:\n",
    "        \n",
    "\n",
    "#for i, x in enumerate(dataloader):\n",
    "    #print(x[0])\n",
    "#Evaluation KS metric\n",
    "# Generate ~300,000 samples and save (NumPy array)\n",
    "# Load ^, 5000 then\n",
    "# KS <-- Root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dis_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_loss.data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (GANS)",
   "language": "python",
   "name": "gans"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
